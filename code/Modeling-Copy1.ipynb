{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Sci-kit libraries\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('../data/wine_beer_concatenated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resources for a newbie home winemaker I want t...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A question about kit wine I’ve made quite a fe...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Riesling - My First Wine Hi Everyone,\\n\\nI am ...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Persimmon Wine Straining? Hello! This is my fi...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wire used for Trellis Hey all - I'm planting s...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext   subreddit\n",
       "0  Resources for a newbie home winemaker I want t...  winemaking\n",
       "1  A question about kit wine I’ve made quite a fe...  winemaking\n",
       "2  Riesling - My First Wine Hi Everyone,\\n\\nI am ...  winemaking\n",
       "3  Persimmon Wine Straining? Hello! This is my fi...  winemaking\n",
       "4  Wire used for Trellis Hey all - I'm planting s...  winemaking"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>Any input on this recipe 6 lb - Pale Malt, Mar...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>Bottling Tepache Hello brewers, \\n\\na couple d...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>Wiring a spa panel for ebiab gfi I've been all...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>What can I ferment at 60-65°F? The basement in...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>Does a decoction mash with wheat leave a bread...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               selftext    subreddit\n",
       "4297  Any input on this recipe 6 lb - Pale Malt, Mar...  Homebrewing\n",
       "4298  Bottling Tepache Hello brewers, \\n\\na couple d...  Homebrewing\n",
       "4299  Wiring a spa panel for ebiab gfi I've been all...  Homebrewing\n",
       "4300  What can I ferment at 60-65°F? The basement in...  Homebrewing\n",
       "4301  Does a decoction mash with wheat leave a bread...  Homebrewing"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homebrewing    2367\n",
       "winemaking     1935\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing subreddit column for targeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['subreddit'] = posts['subreddit'].map({'winemaking': 0, 'Homebrewing': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "**Interpretation**\n",
    "* If we guessed at random we would select Homebrewing subreddit 55% of the time and winemaking subreddit 45% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.550209\n",
       "0    0.449791\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target and Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = posts['selftext']\n",
    "y = posts['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, \n",
    "                                                   random_state = 42, \n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of vectorizers to iterate through with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vects = [CountVectorizer(), TfidfVectorizer()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Vectorizer hyperparameter tuning variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = [300, 5_000]\n",
    "max_df = [.7, .8]\n",
    "min_df = [2, 3]\n",
    "ngram_range = [(1,2), (1,3)]\n",
    "stop_words = [None, 'english']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loop to loop through vectorizers, create a pipeline and loop through potential models while grid search looks for optimal hyperparameters. \n",
    "\n",
    "* Notes from pipeline documentation:\n",
    "* The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
    "* For this, it enables setting parameters of the various steps using their names and the parameter name separated by a '__', as in the example below.\n",
    "* A step's estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to 'passthrough' or ``None``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesopacich/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.88940483 0.89737494 0.88907282 0.89704293 0.88907282 0.8967106\n",
      " 0.88940483 0.8967106  0.87778166 0.88243172 0.87811367 0.88243172\n",
      " 0.87778166 0.88276373 0.87811367 0.88243172 0.88874082 0.89737494\n",
      " 0.88874082 0.89704293 0.88874082 0.8967106  0.88874082 0.8967106\n",
      " 0.87778166 0.88243172 0.87778166 0.88243172 0.87744966 0.88276373\n",
      " 0.87811367 0.88243172 0.8890715  0.90368602 0.88973551 0.90368602\n",
      " 0.88973551 0.90302168 0.88873949 0.90368569 0.90003297 0.9106621\n",
      " 0.90003363 0.91099444 0.89936896 0.90933342 0.89970163 0.90966576\n",
      " 0.89006751 0.90368602 0.88973584 0.90368602 0.8894035  0.90302168\n",
      " 0.89006851 0.90368569 0.9000333  0.9106621  0.9000333  0.91099444\n",
      " 0.89936896 0.90933342 0.89936929 0.90966576 0.89139653 0.90434937\n",
      " 0.89139686 0.90434937 0.89106452 0.90401703 0.89139653 0.90401703\n",
      " 0.89073219 0.89471923 0.89039985 0.89505123 0.89040051 0.89505157\n",
      " 0.89040018 0.89505157 0.89139686 0.90434937 0.89139686 0.90434937\n",
      " 0.89139686 0.90401703 0.89172919 0.90401703 0.89073219 0.89471923\n",
      " 0.89073219 0.89505123 0.89073252 0.89505157 0.89073219 0.89505157\n",
      " 0.89339088 0.90667473 0.89372288 0.90634239 0.89272687 0.90700674\n",
      " 0.89305887 0.90634239 0.90767141 0.91564384 0.90567871 0.91630818\n",
      " 0.9073394  0.91697219 0.90601105 0.91630851 0.89405489 0.90667473\n",
      " 0.89372288 0.90634239 0.89339088 0.90700674 0.89305887 0.90634239\n",
      " 0.90800441 0.91564384 0.90567905 0.91630818 0.90634339 0.91697219\n",
      " 0.90634306 0.91630851 0.88641744 0.89671391 0.88608544 0.89771026\n",
      " 0.88575343 0.8957169  0.88508942 0.89704558 0.91265612 0.91830087\n",
      " 0.91165977 0.91730453 0.91199211 0.91796953 0.9113281  0.91697318\n",
      " 0.88641744 0.89671391 0.8857531  0.89771026 0.88542142 0.8957169\n",
      " 0.88542109 0.89704558 0.91232445 0.91830087 0.91232445 0.91730453\n",
      " 0.91166011 0.91796953 0.91099576 0.91697318 0.88575376 0.89571756\n",
      " 0.88741346 0.89737825 0.88575376 0.89538489 0.88641744 0.89571756\n",
      " 0.9109951  0.91830286 0.90501768 0.91730585 0.91033076 0.91797086\n",
      " 0.90800639 0.91531481 0.88674945 0.89571756 0.88674912 0.89737825\n",
      " 0.88608544 0.89538489 0.88608544 0.89571756 0.91099543 0.91830286\n",
      " 0.9063467  0.91730585 0.91033076 0.91797086 0.90867107 0.91531481\n",
      " 0.89073483 0.90534605 0.8904025  0.90501371 0.89139884 0.9040167\n",
      " 0.89173052 0.90401703 0.91165746 0.92095725 0.91232246 0.92062557\n",
      " 0.91132545 0.9206259  0.91165746 0.9206259  0.89040217 0.90534605\n",
      " 0.89106585 0.90501371 0.89206219 0.9040167  0.89206219 0.90401703\n",
      " 0.91331881 0.92095725 0.91099378 0.92062557 0.91165779 0.9206259\n",
      " 0.91232213 0.9206259  0.87977469 0.88043737 0.87977436 0.88076938\n",
      " 0.87977469 0.88043737 0.88010636 0.88043737 0.76386346 0.74127981\n",
      " 0.76718649 0.74858592 0.76751618 0.74094681 0.76519214 0.74526487\n",
      " 0.88143604 0.88043737 0.88210038 0.88076938 0.88210005 0.88043737\n",
      " 0.88176771 0.88043737 0.77083987 0.74127981 0.77449325 0.74858592\n",
      " 0.77316358 0.74094681 0.77515759 0.74526487 0.89571657 0.91099212\n",
      " 0.89239486 0.91265215 0.89505223 0.91032877 0.8943902  0.90866875\n",
      " 0.91232312 0.91530952 0.90733742 0.91497983 0.91099279 0.91929888\n",
      " 0.90435036 0.91365247 0.89472155 0.90899976 0.89770893 0.90800275\n",
      " 0.89671358 0.91232246 0.89405522 0.90999545 0.90435202 0.91232345\n",
      " 0.90402001 0.91464782 0.90202732 0.91796953 0.90202434 0.91331947\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/jamesopacich/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.89272597 0.9008635  0.8923938  0.90069741 0.89272597 0.9011955\n",
      " 0.89289206 0.90086341 0.87894395 0.88359351 0.87861178 0.8839256\n",
      " 0.87910995 0.88375951 0.87861186 0.88326126 0.89272597 0.9008635\n",
      " 0.89255989 0.90069741 0.89289206 0.9011955  0.89272597 0.90086341\n",
      " 0.87894387 0.88359351 0.87844578 0.8839256  0.87927604 0.88375951\n",
      " 0.87861186 0.88326126 0.91032829 0.92610392 0.91082671 0.92610367\n",
      " 0.91082655 0.92610384 0.91032846 0.92610367 0.94802363 0.94735962\n",
      " 0.9483558  0.94802396 0.94769163 0.94785771 0.94852197 0.94769171\n",
      " 0.91082655 0.92610392 0.90999637 0.92610367 0.91066046 0.92610384\n",
      " 0.90999629 0.92610367 0.94769163 0.94735962 0.94802372 0.94802396\n",
      " 0.94785771 0.94785771 0.94868798 0.94769171 0.91331742 0.92527358\n",
      " 0.91281908 0.92527349 0.91298525 0.92510749 0.91348342 0.92510749\n",
      " 0.89887088 0.90551364 0.89903689 0.90551355 0.89936897 0.90584573\n",
      " 0.8987048  0.90617781 0.91198898 0.92527358 0.91265307 0.92527349\n",
      " 0.9118229  0.92510749 0.91198898 0.92510749 0.8988708  0.90551364\n",
      " 0.89887088 0.90551355 0.89920297 0.90584573 0.8987048  0.90617781\n",
      " 0.92278271 0.93639948 0.92278271 0.93639964 0.92245054 0.93656556\n",
      " 0.92245054 0.93639956 0.97010984 0.9704416  0.96961175 0.96994359\n",
      " 0.97027593 0.96977751 0.97027601 0.97027568 0.92294863 0.93639948\n",
      " 0.92245037 0.93639964 0.92245037 0.93656556 0.92228437 0.93639956\n",
      " 0.96961184 0.9704416  0.96994392 0.96994359 0.97027601 0.96977751\n",
      " 0.97044202 0.97027568 0.90235802 0.91713688 0.90285652 0.91580853\n",
      " 0.90302236 0.91697096 0.90136175 0.91547644 0.96247124 0.96678839\n",
      " 0.9606448  0.96579196 0.96197307 0.96662247 0.95981462 0.96529387\n",
      " 0.90318844 0.91713688 0.90318861 0.91580853 0.90352061 0.91697096\n",
      " 0.90285627 0.91547644 0.96147514 0.96678839 0.95981479 0.96579196\n",
      " 0.96230524 0.96662247 0.95948253 0.96529387 0.90235826 0.91680496\n",
      " 0.90285668 0.91580853 0.9030226  0.91713713 0.90186017 0.91531044\n",
      " 0.96064505 0.96562645 0.95815434 0.96396576 0.96014671 0.96413226\n",
      " 0.95732392 0.96330175 0.90385303 0.91680496 0.90318877 0.91580853\n",
      " 0.90401912 0.91713713 0.9035207  0.91531044 0.96097722 0.96562645\n",
      " 0.95848643 0.96396576 0.96047888 0.96413226 0.95798801 0.96330175\n",
      " 0.98256393 0.98239793 0.98289602 0.98239785 0.98256393 0.98223193\n",
      " 0.98272993 0.98239785 0.99634687 0.99501843 0.99651287 0.99501843\n",
      " 0.99634687 0.99501843 0.99634687 0.99501843 0.9830621  0.98239793\n",
      " 0.98272993 0.98239785 0.98289602 0.98223193 0.98289602 0.98239785\n",
      " 0.99651287 0.99501843 0.99634687 0.99501843 0.99634678 0.99501843\n",
      " 0.99634687 0.99501843 0.99767522 0.99701121 0.99750913 0.99651295\n",
      " 0.99767522 0.99701121 0.99750913 0.99651295 0.999834   0.99966799\n",
      " 0.999834   0.99916982 0.999834   0.99950199 0.999834   0.99933591\n",
      " 0.99750922 0.99701121 0.99734313 0.99651295 0.99750922 0.99701121\n",
      " 0.99750913 0.99651295 0.999834   0.99966799 0.999834   0.99916982\n",
      " 0.999834   0.99950199 0.999834   0.99933591 0.99784106 0.99618078\n",
      " 0.99717721 0.99584861 0.99734338 0.99618078 0.99767555 0.99568252\n",
      " 0.99966799 0.99966791 0.99950191 0.99950199 0.999834   0.99916974\n",
      " 0.99950191 0.99966791 0.99850548 0.99618078 0.99817331 0.9955166\n",
      " 0.99817347 0.99634695 0.99800747 0.99651287 0.999834   0.99966791\n",
      " 0.99966799 0.99900382 0.99966791 0.99950191 0.99950183 0.99933582\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for Tf-IDF Vectorizer is:\n",
      "        0.921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an empty results list to capture cv_results_ at the end of each iteration. \n",
    "vectorizer_results = []\n",
    "\n",
    "# loop through both vectorizers\n",
    "for vect in vects:\n",
    "\n",
    "\n",
    "    # Create a pipeline for vectorizer and classifier models\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Generate parameters for vectorizer\n",
    "    vect_params = {\n",
    "        'vect__max_features': max_features, \n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df': min_df,\n",
    "        'vect__stop_words': stop_words,\n",
    "        'vect__ngram_range': ngram_range\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Create a list of dictionaries that contain parameters for each classifier/model \n",
    "    parameters = [\n",
    "    {\n",
    "        #Log Regression\n",
    "        'vect__max_features': max_features, \n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df': min_df,\n",
    "        'vect__stop_words': stop_words,\n",
    "        'vect__ngram_range': ngram_range,\n",
    "        'clf': (LogisticRegression(solver = 'liblinear'), ),\n",
    "        'clf__penalty': ('l1', 'l2'),\n",
    "        'clf__C': (.5, 1.0)\n",
    "        \n",
    "    },\n",
    "        \n",
    "    {#Multinomial Bayes\n",
    "        'vect__max_features': max_features, \n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df': min_df,\n",
    "        'vect__stop_words': stop_words,\n",
    "        'vect__ngram_range': ngram_range,\n",
    "        'clf': (MultinomialNB(), ),\n",
    "        'clf__alpha': (.5, 1.0)\n",
    "    },\n",
    "        \n",
    "    {\n",
    "        #SVC\n",
    "        'vect__max_features': max_features, \n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df': min_df,\n",
    "        'vect__stop_words': stop_words,\n",
    "        'vect__ngram_range': ngram_range,\n",
    "        'clf': (SVC(gamma = 'scale', ), ),\n",
    "        'clf__kernel': ('rbf', 'poly')\n",
    "        \n",
    "           \n",
    "    },\n",
    "        \n",
    "    {\n",
    "        #Random Forest Classifier\n",
    "        'vect__max_features': max_features, \n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df': min_df,\n",
    "        'vect__stop_words': stop_words,\n",
    "        'vect__ngram_range': ngram_range,\n",
    "        'clf': (RandomForestClassifier(n_estimators = 50, min_samples_split = 5), )\n",
    "          \n",
    "    },\n",
    "        \n",
    "    {\n",
    "        #Ensemble Model\n",
    "        'vect__max_features': max_features, \n",
    "        'vect__max_df': max_df,\n",
    "        'vect__min_df': min_df,\n",
    "        'vect__stop_words': stop_words,\n",
    "        'vect__ngram_range': ngram_range,\n",
    "        'clf': (VotingClassifier(estimators = [('lr', LogisticRegression()),\n",
    "                                               ('mnb', MultinomialNB()),\n",
    "                                               ('rf', RandomForestClassifier()),\n",
    "                                               ('svc', SVC())],\n",
    "                                 voting = 'soft'), )\n",
    "        \n",
    "   \n",
    "    }\n",
    "        \n",
    "        \n",
    "    ] \n",
    "    # Perform grid search with the inherited pipeline and parameters\n",
    "    grid_search = GridSearchCV(pipeline,\n",
    "                               parameters,\n",
    "                               cv=3,\n",
    "                               n_jobs =-1,\n",
    "                               verbose =2,\n",
    "                               return_train_score =True)\n",
    "    \n",
    "    # Print the type of vectorizer used by running an if statement\n",
    "    if vect == vects[0]:\n",
    "        vect_string = 'Count Vectorizer'\n",
    "    else:\n",
    "        vect_string = 'Tf-IDF Vectorizer'\n",
    "    # Fit model and print best scores and parameters\n",
    "        #Fit\n",
    "        grid_search.fit(X_train, y_train)\n",
    "    \n",
    "        #print\n",
    "        print(f'''Best score for {vect_string} is:\n",
    "        {round(grid_search.best_score_, 4)}''')\n",
    "        print('')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append cv_results_ to the end of the results. \n",
    "    vectorizer_results.append(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Metrics With Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity/Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
