{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Sci-kit libraries\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Sci-kit Modeling Libraries\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "#Sci-kit Metric Libraries\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve, auc, f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('../data/wine_beer_concatenated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resources for a newbie home winemaker I want t...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext   subreddit\n",
       "0  Resources for a newbie home winemaker I want t...  winemaking"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>Does a decoction mash with wheat leave a bread...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               selftext    subreddit\n",
       "4301  Does a decoction mash with wheat leave a bread...  Homebrewing"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homebrewing    2367\n",
       "winemaking     1935\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing subreddit column for targeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['subreddit'] = posts['subreddit'].map({'winemaking': 0, 'Homebrewing': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2367\n",
       "0    1935\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target and Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = posts['selftext']\n",
    "y = posts['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, \n",
    "                                                   random_state = 42, \n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a list of our two chosen vectorizers to iterate through in our grid search\n",
    "vectorizer = [CountVectorizer(), TfidfVectorizer()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating variables to accept tuning parameters\n",
    "max_feat = [300, 500]  \n",
    "ngram_range = [(1, 3), (1, 2)] \n",
    "stop_words = [None, 'english'] \n",
    "max_df = [0.9, 0.8] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loop to loop through vectorizers, create a pipeline and loop through potential models while grid search looks for optimal hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on setting voting classifier parameter to 'soft' or 'hard'. https://towardsdatascience.com/how-voting-classifiers-work-f1c8e41d30ff\n",
    "\n",
    "Soft on even number of classifiers. Hard on odd number of classifiers. Since I am using 4 classifiers I tried to set it to soft but kept getting error messages. I am imagining one of the classifiers is not working well with 'soft.' I returned to using 'hard' and it worked fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n",
      "Best score for CountVectorizer is: \n",
      "    0.9176\n",
      "    \n",
      "{'clf': VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
      "                             ('rf', RandomForestClassifier()),\n",
      "                             ('mnb', MultinomialNB()), ('svc', SVC())]), 'vect__max_df': 0.9, 'vect__max_features': 300, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n",
      "Best score for Tf-IDF Vectorizer is: \n",
      "    0.9166\n",
      "    \n",
      "{'clf': VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
      "                             ('rf', RandomForestClassifier()),\n",
      "                             ('mnb', MultinomialNB()), ('svc', SVC())]), 'vect__max_df': 0.8, 'vect__max_features': 500, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## creating any empty results list to capture our cv_results_ at the end of each iteration\n",
    "results = []\n",
    "\n",
    "## looping through both vectorizers\n",
    "for vect in vectorizer:\n",
    "    \n",
    "    #### Pipeline for our Vectorizer and Classifier Models ####\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', LogisticRegression())])\n",
    "    \n",
    "    instantiations = [ #### Beginning of Instantiations List ####\n",
    "        {\n",
    "            ### Log Reg Vect Hyperparameters ###\n",
    "            \n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiate Log Reg and Hyperparamaters\n",
    "            'clf': (LogisticRegression(solver='liblinear'), ), ## setting our first classifier model\n",
    "            'clf__penalty': ('l1', 'l2'),\n",
    "            'clf__C': (.5, 1.0), \n",
    "        }, \n",
    "    #######\n",
    "        {\n",
    "            \n",
    "            ### Multinomial Bayes Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiate Mulinomial NB and Hyperparamters ##\n",
    "            'clf': (MultinomialNB(), ),  \n",
    "            'clf__alpha': (.5, 1.0)\n",
    "        },\n",
    "    #######   \n",
    "        {\n",
    "            ### SVC Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## SVC Instantiation and Hyperparameters\n",
    "            'clf': (SVC(gamma='scale', ), ),\n",
    "            'clf__kernel': ('rbf', 'poly') \n",
    "        },\n",
    "    #######  \n",
    "        {\n",
    "            ### RandomForestClassifier Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiate RandomForestClassifier ##\n",
    "            'clf': (RandomForestClassifier(n_estimators=50, min_samples_split=5), ),\n",
    "        },\n",
    "    #######\n",
    "        {\n",
    "            ### Voting Classifier Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiating Ensemble Voting Classifier ##\n",
    "            'clf': (VotingClassifier(estimators=[('lr', LogisticRegression()), \n",
    "                                                 ('rf', RandomForestClassifier()), \n",
    "                                                 ('mnb', MultinomialNB()), \n",
    "                                                 ('svc', SVC())],                                           \n",
    "                                            voting='hard'), )\n",
    "        }    \n",
    "                    ] #### end of instantiations list ####\n",
    "    \n",
    "    \n",
    "    #### Grid Search ####\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, \n",
    "                               instantiations,\n",
    "                               cv=3,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=3,\n",
    "                               return_train_score=True)\n",
    "    \n",
    "    #### Output Results ####\n",
    "    \n",
    "    ## running an if statement to print the type of vectorizer used\n",
    "    if vect == vectorizer[0]:\n",
    "        vect_string = \"CountVectorizer\"\n",
    "    \n",
    "    else:\n",
    "        vect_string = \"Tf-IDF Vectorizer\"\n",
    "    \n",
    "    ## fitting our model and printing our best scores and parameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f'''Best score for {vect_string} is: \n",
    "    {round(grid_search.best_score_, 4)}\n",
    "    ''')\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\")\n",
    "    \n",
    "    ## appending our cv_results_ to the end of results\n",
    "    results.append(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_vect__max_df</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.173456</td>\n",
       "      <td>0.088117</td>\n",
       "      <td>0.82536</td>\n",
       "      <td>0.030476</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886454</td>\n",
       "      <td>0.886341</td>\n",
       "      <td>0.886748</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>139</td>\n",
       "      <td>0.891878</td>\n",
       "      <td>0.884903</td>\n",
       "      <td>0.895916</td>\n",
       "      <td>0.890899</td>\n",
       "      <td>0.004549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       5.173456      0.088117          0.82536        0.030476   \n",
       "\n",
       "                                param_clf param_clf__C param_clf__penalty  \\\n",
       "0  LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "\n",
       "  param_vect__max_df param_vect__max_features param_vect__ngram_range  ...  \\\n",
       "0                0.9                      300                  (1, 3)  ...   \n",
       "\n",
       "  split1_test_score split2_test_score mean_test_score std_test_score  \\\n",
       "0          0.886454          0.886341        0.886748       0.000498   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0              139            0.891878            0.884903   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.895916          0.890899         0.004549  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['train_test_var'] = abs(results_df['mean_test_score'] - results_df['mean_train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.004151\n",
       "1      0.004153\n",
       "2      0.003652\n",
       "3      0.004153\n",
       "4      0.004318\n",
       "         ...   \n",
       "155    0.063768\n",
       "156    0.068417\n",
       "157    0.063931\n",
       "158    0.069413\n",
       "159    0.067916\n",
       "Name: train_test_var, Length: 160, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['train_test_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf</th>\n",
       "      <th>train_test_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.003652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.003985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.015279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.015777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.015778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.015944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.016605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.017435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.017601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.017601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.017767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 param_clf  train_test_var\n",
       "2   LogisticRegression(solver='liblinear')        0.003652\n",
       "8   LogisticRegression(solver='liblinear')        0.003985\n",
       "0   LogisticRegression(solver='liblinear')        0.004151\n",
       "10  LogisticRegression(solver='liblinear')        0.004151\n",
       "6   LogisticRegression(solver='liblinear')        0.004152\n",
       "1   LogisticRegression(solver='liblinear')        0.004153\n",
       "9   LogisticRegression(solver='liblinear')        0.004153\n",
       "3   LogisticRegression(solver='liblinear')        0.004153\n",
       "11  LogisticRegression(solver='liblinear')        0.004153\n",
       "4   LogisticRegression(solver='liblinear')        0.004318\n",
       "12  LogisticRegression(solver='liblinear')        0.004485\n",
       "14  LogisticRegression(solver='liblinear')        0.004485\n",
       "5   LogisticRegression(solver='liblinear')        0.006975\n",
       "7   LogisticRegression(solver='liblinear')        0.006975\n",
       "13  LogisticRegression(solver='liblinear')        0.006975\n",
       "15  LogisticRegression(solver='liblinear')        0.006975\n",
       "46  LogisticRegression(solver='liblinear')        0.015279\n",
       "44  LogisticRegression(solver='liblinear')        0.015777\n",
       "36  LogisticRegression(solver='liblinear')        0.015778\n",
       "38  LogisticRegression(solver='liblinear')        0.015944\n",
       "88                         MultinomialNB()        0.016605\n",
       "74                         MultinomialNB()        0.017435\n",
       "64                         MultinomialNB()        0.017601\n",
       "72                         MultinomialNB()        0.017601\n",
       "80                         MultinomialNB()        0.017767"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[: ,['param_clf', 'train_test_var']].nsmallest(25, 'train_test_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('../data/scores_1.xlsx', engine = 'xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Metrics With Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity/Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
