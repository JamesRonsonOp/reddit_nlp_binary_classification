{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Sci-kit libraries\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('../data/wine_beer_concatenated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resources for a newbie home winemaker I want t...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A question about kit wine I’ve made quite a fe...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Riesling - My First Wine Hi Everyone,\\n\\nI am ...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Persimmon Wine Straining? Hello! This is my fi...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wire used for Trellis Hey all - I'm planting s...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext   subreddit\n",
       "0  Resources for a newbie home winemaker I want t...  winemaking\n",
       "1  A question about kit wine I’ve made quite a fe...  winemaking\n",
       "2  Riesling - My First Wine Hi Everyone,\\n\\nI am ...  winemaking\n",
       "3  Persimmon Wine Straining? Hello! This is my fi...  winemaking\n",
       "4  Wire used for Trellis Hey all - I'm planting s...  winemaking"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>Any input on this recipe 6 lb - Pale Malt, Mar...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>Bottling Tepache Hello brewers, \\n\\na couple d...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>Wiring a spa panel for ebiab gfi I've been all...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>What can I ferment at 60-65°F? The basement in...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>Does a decoction mash with wheat leave a bread...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               selftext    subreddit\n",
       "4297  Any input on this recipe 6 lb - Pale Malt, Mar...  Homebrewing\n",
       "4298  Bottling Tepache Hello brewers, \\n\\na couple d...  Homebrewing\n",
       "4299  Wiring a spa panel for ebiab gfi I've been all...  Homebrewing\n",
       "4300  What can I ferment at 60-65°F? The basement in...  Homebrewing\n",
       "4301  Does a decoction mash with wheat leave a bread...  Homebrewing"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homebrewing    2367\n",
       "winemaking     1935\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing subreddit column for targeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['subreddit'] = posts['subreddit'].map({'winemaking': 0, 'Homebrewing': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2367\n",
       "0    1935\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "**Interpretation**\n",
    "* If we guessed at random we would select Homebrewing subreddit 55% of the time and winemaking subreddit 45% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.550209\n",
       "0    0.449791\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target and Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = posts['selftext']\n",
    "y = posts['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, \n",
    "                                                   random_state = 42, \n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a list of our two chosen vectorizers to iterate through in our grid search\n",
    "vectorizer = [CountVectorizer(), TfidfVectorizer()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating variables to accept tuning parameters\n",
    "max_feat = [300, 500]  \n",
    "ngram_range = [(1, 3), (1, 2)] \n",
    "stop_words = [None, 'english'] \n",
    "max_df = [0.9, 0.8] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loop to loop through vectorizers, create a pipeline and loop through potential models while grid search looks for optimal hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on setting voting classifier parameter to 'soft' or 'hard'. https://towardsdatascience.com/how-voting-classifiers-work-f1c8e41d30ff\n",
    "\n",
    "Soft on even number of classifiers. Hard on odd number of classifiers. Since I am using 4 classifiers I tried to set it to soft but kept getting error messages. I am imagining one of the classifiers is not working well with 'soft.' I returned to using 'hard' and it worked fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n",
      "Best score for CountVectorizer is: \n",
      "    0.9173\n",
      "    \n",
      "{'clf': VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
      "                             ('rf', RandomForestClassifier()),\n",
      "                             ('mnb', MultinomialNB()), ('svc', SVC())]), 'vect__max_df': 0.8, 'vect__max_features': 500, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n",
      "Best score for Tf-IDF Vectorizer is: \n",
      "    0.9156\n",
      "    \n",
      "{'clf': VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
      "                             ('rf', RandomForestClassifier()),\n",
      "                             ('mnb', MultinomialNB()), ('svc', SVC())]), 'vect__max_df': 0.9, 'vect__max_features': 500, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## creating any empty results list to capture our cv_results_ at the end of each iteration\n",
    "results = []\n",
    "\n",
    "## looping through both vectorizers\n",
    "for vect in vectorizer:\n",
    "    \n",
    "    #### Pipeline for our Vectorizer and Classifier Models ####\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', LogisticRegression())])\n",
    "    \n",
    "    instantiations = [ #### Beginning of Instantiations List ####\n",
    "        {\n",
    "            ### Log Reg Vect Hyperparameters ###\n",
    "            \n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiate Log Reg and Hyperparamaters\n",
    "            'clf': (LogisticRegression(solver='liblinear'), ), ## setting our first classifier model\n",
    "            'clf__penalty': ('l1', 'l2'),\n",
    "            'clf__C': (.5, 1.0), \n",
    "        }, \n",
    "    #######\n",
    "        {\n",
    "            \n",
    "            ### Multinomial Bayes Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiate Mulinomial NB and Hyperparamters ##\n",
    "            'clf': (MultinomialNB(), ),  \n",
    "            'clf__alpha': (.5, 1.0)\n",
    "        },\n",
    "    #######   \n",
    "        {\n",
    "            ### SVC Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## SVC Instantiation and Hyperparameters\n",
    "            'clf': (SVC(gamma='scale', ), ),\n",
    "            'clf__kernel': ('rbf', 'poly') \n",
    "        },\n",
    "    #######  \n",
    "        {\n",
    "            ### RandomForestClassifier Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiate RandomForestClassifier ##\n",
    "            'clf': (RandomForestClassifier(n_estimators=50, min_samples_split=5), ),\n",
    "        },\n",
    "    #######\n",
    "        {\n",
    "            ### Voting Classifier Vect Hyperparameters ###\n",
    "            'vect__max_features': max_feat,\n",
    "            'vect__stop_words': stop_words,\n",
    "            'vect__ngram_range': ngram_range,\n",
    "            'vect__max_df': max_df,\n",
    "            \n",
    "            ## Instantiating Ensemble Voting Classifier ##\n",
    "            'clf': (VotingClassifier(estimators=[('lr', LogisticRegression()), \n",
    "                                                 ('rf', RandomForestClassifier()), \n",
    "                                                 ('mnb', MultinomialNB()), \n",
    "                                                 ('svc', SVC())],                                           \n",
    "                                            voting='hard'), )\n",
    "        }    \n",
    "                    ] #### end of instantiations list ####\n",
    "    \n",
    "    \n",
    "    #### Grid Search ####\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, \n",
    "                               instantiations,\n",
    "                               cv=3,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=1,\n",
    "                               return_train_score=True)\n",
    "    \n",
    "    #### Output Results ####\n",
    "    \n",
    "    ## running an if statement to print the type of vectorizer used\n",
    "    if vect == vectorizer[0]:\n",
    "        vect_string = \"CountVectorizer\"\n",
    "    \n",
    "    else:\n",
    "        vect_string = \"Tf-IDF Vectorizer\"\n",
    "    \n",
    "    ## fitting our model and printing our best scores and parameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f'''Best score for {vect_string} is: \n",
    "    {round(grid_search.best_score_, 4)}\n",
    "    ''')\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\")\n",
    "    \n",
    "    ## appending our cv_results_ to the end of results\n",
    "    results.append(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_vect__max_df</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.337792</td>\n",
       "      <td>0.097530</td>\n",
       "      <td>1.525834</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886454</td>\n",
       "      <td>0.886341</td>\n",
       "      <td>0.886748</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>139</td>\n",
       "      <td>0.891878</td>\n",
       "      <td>0.884903</td>\n",
       "      <td>0.895916</td>\n",
       "      <td>0.890899</td>\n",
       "      <td>0.004549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.195457</td>\n",
       "      <td>0.659931</td>\n",
       "      <td>0.798023</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904382</td>\n",
       "      <td>0.892323</td>\n",
       "      <td>0.896711</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>90</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.899851</td>\n",
       "      <td>0.901394</td>\n",
       "      <td>0.900863</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.397391</td>\n",
       "      <td>0.182171</td>\n",
       "      <td>1.160251</td>\n",
       "      <td>0.136918</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886454</td>\n",
       "      <td>0.888335</td>\n",
       "      <td>0.887413</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>135</td>\n",
       "      <td>0.891878</td>\n",
       "      <td>0.885401</td>\n",
       "      <td>0.895916</td>\n",
       "      <td>0.891065</td>\n",
       "      <td>0.004331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.556233</td>\n",
       "      <td>0.082449</td>\n",
       "      <td>0.717388</td>\n",
       "      <td>0.031691</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904382</td>\n",
       "      <td>0.892323</td>\n",
       "      <td>0.897043</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>86</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.900349</td>\n",
       "      <td>0.901892</td>\n",
       "      <td>0.901196</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.100743</td>\n",
       "      <td>0.091858</td>\n",
       "      <td>1.513699</td>\n",
       "      <td>0.134462</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.885344</td>\n",
       "      <td>0.888408</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>132</td>\n",
       "      <td>0.890882</td>\n",
       "      <td>0.892875</td>\n",
       "      <td>0.894422</td>\n",
       "      <td>0.892726</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       8.337792      0.097530         1.525834        0.012855   \n",
       "1       6.195457      0.659931         0.798023        0.024647   \n",
       "2       4.397391      0.182171         1.160251        0.136918   \n",
       "3       3.556233      0.082449         0.717388        0.031691   \n",
       "4       9.100743      0.091858         1.513699        0.134462   \n",
       "\n",
       "                                param_clf param_clf__C param_clf__penalty  \\\n",
       "0  LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "1  LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "2  LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "3  LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "4  LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "\n",
       "  param_vect__max_df param_vect__max_features param_vect__ngram_range  ...  \\\n",
       "0                0.9                      300                  (1, 3)  ...   \n",
       "1                0.9                      300                  (1, 3)  ...   \n",
       "2                0.9                      300                  (1, 2)  ...   \n",
       "3                0.9                      300                  (1, 2)  ...   \n",
       "4                0.9                      500                  (1, 3)  ...   \n",
       "\n",
       "  split1_test_score split2_test_score mean_test_score std_test_score  \\\n",
       "0          0.886454          0.886341        0.886748       0.000498   \n",
       "1          0.904382          0.892323        0.896711       0.005443   \n",
       "2          0.886454          0.888335        0.887413       0.000768   \n",
       "3          0.904382          0.892323        0.897043       0.005260   \n",
       "4          0.891434          0.885344        0.888408       0.002486   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0              139            0.891878            0.884903   \n",
       "1               90            0.901345            0.899851   \n",
       "2              135            0.891878            0.885401   \n",
       "3               86            0.901345            0.900349   \n",
       "4              132            0.890882            0.892875   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.895916          0.890899         0.004549  \n",
       "1            0.901394          0.900863         0.000717  \n",
       "2            0.895916          0.891065         0.004331  \n",
       "3            0.901892          0.901196         0.000639  \n",
       "4            0.894422          0.892726         0.001449  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Metrics With Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity/Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
