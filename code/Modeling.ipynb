{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Sci-kit libraries\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('../data/wine_beer_concatenated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resources for a newbie home winemaker I want t...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A question about kit wine I’ve made quite a fe...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Riesling - My First Wine Hi Everyone,\\n\\nI am ...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Persimmon Wine Straining? Hello! This is my fi...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wire used for Trellis Hey all - I'm planting s...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext   subreddit\n",
       "0  Resources for a newbie home winemaker I want t...  winemaking\n",
       "1  A question about kit wine I’ve made quite a fe...  winemaking\n",
       "2  Riesling - My First Wine Hi Everyone,\\n\\nI am ...  winemaking\n",
       "3  Persimmon Wine Straining? Hello! This is my fi...  winemaking\n",
       "4  Wire used for Trellis Hey all - I'm planting s...  winemaking"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>Any input on this recipe 6 lb - Pale Malt, Mar...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>Bottling Tepache Hello brewers, \\n\\na couple d...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>Wiring a spa panel for ebiab gfi I've been all...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>What can I ferment at 60-65°F? The basement in...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>Does a decoction mash with wheat leave a bread...</td>\n",
       "      <td>Homebrewing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               selftext    subreddit\n",
       "4297  Any input on this recipe 6 lb - Pale Malt, Mar...  Homebrewing\n",
       "4298  Bottling Tepache Hello brewers, \\n\\na couple d...  Homebrewing\n",
       "4299  Wiring a spa panel for ebiab gfi I've been all...  Homebrewing\n",
       "4300  What can I ferment at 60-65°F? The basement in...  Homebrewing\n",
       "4301  Does a decoction mash with wheat leave a bread...  Homebrewing"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homebrewing    2367\n",
       "winemaking     1935\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing subreddit column for targeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['subreddit'] = posts['subreddit'].map({'winemaking': 0, 'Homebrewing': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2367\n",
       "0    1935\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "**Interpretation**\n",
    "* If we guessed at random we would select Homebrewing subreddit 55% of the time and winemaking subreddit 45% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.550209\n",
       "0    0.449791\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target and Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = posts['selftext']\n",
    "y = posts['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, \n",
    "                                                   random_state = 42, \n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of vectorizers for grid search to iterate through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of our two chosen vectorizers to iterate through in our grid search\n",
    "vects = [CountVectorizer(), TfidfVectorizer()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating hyperparameter tuning variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating variables to accept tuning parameters\n",
    "max_feat = [300, 500]\n",
    "ngram_range = [(1,3), (1,2)]\n",
    "stop_words = [None, 'english']\n",
    "max_df = [.9, .8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loop to loop through vectorizers, create a pipeline and loop through potential models while grid search looks for optimal hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on setting voting classifier parameter to 'soft' or 'hard'. https://towardsdatascience.com/how-voting-classifiers-work-f1c8e41d30ff\n",
    "\n",
    "Soft on even number of classifiers. Hard on odd number of classifiers. Since I am using 4 classifiers I will set it to soft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesopacich/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.88508512 0.90003098 0.88608113 0.89969898 0.89139587 0.90235436\n",
      " 0.89073185 0.90235436 0.88674514 0.90003098 0.88807316 0.89969898\n",
      " 0.89006784 0.90235436 0.89039985 0.90268669 0.87612097 0.89172721\n",
      " 0.87645364 0.89205888 0.87246395 0.89671292 0.87080392 0.8957169\n",
      " 0.87512396 0.89172721 0.87479229 0.89205888 0.87379429 0.89671292\n",
      " 0.87412629 0.8957169  0.87645165 0.88874015 0.87678333 0.88840815\n",
      " 0.87844402 0.8947179  0.87678366 0.89305788 0.87578698 0.88907216\n",
      " 0.876783   0.88907249 0.87944003 0.8947179  0.87910836 0.89305788\n",
      " 0.86814987 0.88940251 0.86947855 0.88973451 0.86582417 0.89040184\n",
      " 0.8654925  0.89040084 0.86881388 0.88940251 0.86848088 0.88973451\n",
      " 0.86715253 0.89040184 0.86648818 0.89040084 0.88708211 0.90468402\n",
      " 0.88542109 0.90435135 0.90202765 0.90435268 0.903024   0.90700938\n",
      " 0.88542176 0.90468402 0.88575343 0.90435135 0.90103163 0.90435268\n",
      " 0.90169597 0.90700938 0.88708244 0.90402001 0.88608577 0.90368734\n",
      " 0.90235965 0.90534903 0.903024   0.90700938 0.88575409 0.90402001\n",
      " 0.88575343 0.90368734 0.90169564 0.90534903 0.90235999 0.90700938\n",
      " 0.86516248 0.88741279 0.86549482 0.88708046 0.86715319 0.89106684\n",
      " 0.86682085 0.88940648 0.87014355 0.88741279 0.87080756 0.88708046\n",
      " 0.87313094 0.89106684 0.87313094 0.88940648 0.69511816 0.71205871\n",
      " 0.69511816 0.71205871 0.69279247 0.69545149 0.69212813 0.69545149\n",
      " 0.70242394 0.71205871 0.70142825 0.71205871 0.69478517 0.69545149\n",
      " 0.69445316 0.69545149 0.8914005  0.90933276 0.89637959 0.9096651\n",
      " 0.90069863 0.91331947 0.90135934 0.91032877 0.89206219 0.90335203\n",
      " 0.8930602  0.90601039 0.89870429 0.90866875 0.89803961 0.9099971\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/jamesopacich/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.9368979  0.94204588 0.93673173 0.9418798  0.95665875 0.95200877\n",
      " 0.95632658 0.95200877 0.93606747 0.94221197 0.93739616 0.9418798\n",
      " 0.9556624  0.95184269 0.9556624  0.95200877 0.94387249 0.95300578\n",
      " 0.94287606 0.95200927 0.96927867 0.97160412 0.97044127 0.97110586\n",
      " 0.94320799 0.95300578 0.94486867 0.95200927 0.97110545 0.97160412\n",
      " 0.97044111 0.97110586 0.94387266 0.95151126 0.9433744  0.95151126\n",
      " 0.97027519 0.96961126 0.97060736 0.96894692 0.94370624 0.95167735\n",
      " 0.94453675 0.95167735 0.969279   0.96977734 0.96861483 0.969113\n",
      " 0.94636328 0.95566323 0.9465292  0.95533106 0.97708336 0.97741603\n",
      " 0.97774762 0.97658569 0.94686112 0.95566323 0.94752529 0.95533106\n",
      " 0.97691744 0.97741603 0.97691753 0.97658569 0.90269043 0.91597387\n",
      " 0.90335469 0.91663805 0.91680463 0.92411115 0.91863149 0.92361289\n",
      " 0.90202642 0.91597387 0.90418537 0.91663805 0.91680463 0.92411115\n",
      " 0.91730289 0.92361289 0.90202609 0.91580779 0.90269035 0.91680413\n",
      " 0.91630646 0.92344697 0.91796723 0.92361297 0.90186034 0.91580779\n",
      " 0.90368719 0.91680413 0.91647246 0.92344697 0.91746897 0.92361297\n",
      " 0.90717317 0.94005336 0.90750517 0.93972119 0.91663871 0.94619694\n",
      " 0.91663871 0.94619711 0.919295   0.94005336 0.919295   0.93972119\n",
      " 0.93091974 0.94619694 0.93075373 0.94619711 0.73513693 0.76552509\n",
      " 0.73463867 0.76535901 0.73297807 0.75489745 0.73281198 0.75473145\n",
      " 0.75871675 0.76552509 0.75871675 0.76535901 0.75273867 0.75489745\n",
      " 0.75257267 0.75473145 0.993856   0.98987069 0.99402184 0.99352391\n",
      " 0.99584886 0.99452001 0.99468618 0.99385592 0.99435417 0.99269348\n",
      " 0.99501851 0.9925274  0.99468626 0.99269332 0.99435392 0.99269332\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for (vect_string) is:\n",
      "    0.9133\n",
      "{'clf': RandomForestClassifier(min_samples_split=5, n_estimators=50), 'cvec__max_df': 0.9, 'cvec__max_features': 500, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english'}\n",
      "\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d54564f4173f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Fitting model and printing best scores and parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     print(f'''Best score for (vect_string) is:\n\u001b[1;32m     95\u001b[0m     {round(grid_search.best_score_, 4)}''')\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create any empty results list to capture our cv_results_ at the end of each iteration\n",
    "results = []\n",
    "\n",
    "## looping through both vectorizers\n",
    "for vect in vects:\n",
    "    \n",
    "    # create a pipeline for our vectorizer and classifier models\n",
    "    pipeline = Pipeline([\n",
    "        ('cvec', vect),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    ## generating our parameters for vectorizers\n",
    "    vect_params = {'cvec__max_features': max_feat, \n",
    "                  'cvec__stop_words': stop_words,\n",
    "                   'cvec__ngram_range': ngram_range,\n",
    "                   'cvec__max_df': max_df\n",
    "                  }\n",
    "    parameters = [\n",
    "        {\n",
    "            ## Logistic Regression (1st model)\n",
    "            'cvec__max_features': max_feat,\n",
    "            'cvec__stop_words': stop_words,\n",
    "            'cvec__ngram_range': ngram_range,\n",
    "            'cvec__max_df': max_df,\n",
    "            'clf': (LogisticRegression(solver = 'liblinear'), ),\n",
    "            'clf__penalty': ('l1', 'l2'), \n",
    "            'clf__C': (.5, 1)\n",
    "            \n",
    "        }, \n",
    "        {\n",
    "        \n",
    "            ## Multinomial Bayes\n",
    "            'cvec__max_features': max_feat,\n",
    "            'cvec__stop_words': stop_words, \n",
    "            'cvec__ngram_range': ngram_range, \n",
    "            'cvec__max_df': max_df,\n",
    "            'clf': (MultinomialNB(), ), \n",
    "            'clf__alpha': (.5, 1.0)\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            ## SVC\n",
    "            'cvec__max_features': max_feat,\n",
    "            'cvec__stop_words': stop_words,\n",
    "            'cvec__ngram_range': ngram_range,\n",
    "            'cvec__max_df': max_df,\n",
    "            'clf': (SVC(gamma='scale', ), ),\n",
    "            'clf__kernel': ('rbf', 'poly')\n",
    "        },\n",
    "        {\n",
    "            ## Random Forest Classifier\n",
    "            'cvec__max_features': max_feat,\n",
    "            'cvec__stop_words': stop_words,\n",
    "            'cvec__ngram_range': ngram_range,\n",
    "            'cvec__max_df': max_df,\n",
    "            'clf': (RandomForestClassifier(n_estimators = 50, min_samples_split = 5), ), \n",
    "        },\n",
    "        {\n",
    "            ## Ensemble Model\n",
    "            'cvec__max_features': max_feat,\n",
    "            'cvec__stop_words': stop_words, \n",
    "            'cvec__ngram_range': ngram_range,\n",
    "            'cvec__max_df': max_df,\n",
    "            'clf': (VotingClassifier(estimators = [('lr', LogisticRegression()),\n",
    "                                                   ('rf', RandomForestClassifier()),\n",
    "                                                   ('mnb', MultinomialNB()),\n",
    "                                                   ('svc', SVC())],\n",
    "                                                    voting = 'soft'), )\n",
    "        }\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Grid Search with inherited pipeline and parameters\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        parameters,\n",
    "        cv=3,\n",
    "        n_jobs = -1,\n",
    "        verbose = 1,\n",
    "        return_train_score = True\n",
    "                              )\n",
    "    \n",
    "    # runing an if statement to print the type of vectorizer used\n",
    "    if vect == vects[0]:\n",
    "        vect_string = 'CountVectorizer'\n",
    "        \n",
    "    else:\n",
    "        vect_string = 'Tf-IDF Vectorizer'\n",
    "        \n",
    "    # Fitting model and printing best scores and parameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f'''Best score for (vect_string) is:\n",
    "    {round(grid_search.best_score_, 4)}''')\n",
    "    print(grid_search.best_params_)\n",
    "    print('')\n",
    "    \n",
    "    # appending cv_results_ to the end of results\n",
    "    results.append(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_vect__max_df</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.633313</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.486775</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886454</td>\n",
       "      <td>0.886341</td>\n",
       "      <td>0.886748</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>138</td>\n",
       "      <td>0.891380</td>\n",
       "      <td>0.884903</td>\n",
       "      <td>0.895916</td>\n",
       "      <td>0.890733</td>\n",
       "      <td>0.004519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.359614</td>\n",
       "      <td>0.121083</td>\n",
       "      <td>0.430986</td>\n",
       "      <td>0.145028</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904382</td>\n",
       "      <td>0.893320</td>\n",
       "      <td>0.897043</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>86</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.899851</td>\n",
       "      <td>0.900896</td>\n",
       "      <td>0.900697</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.363829</td>\n",
       "      <td>0.124363</td>\n",
       "      <td>0.471265</td>\n",
       "      <td>0.077995</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887450</td>\n",
       "      <td>0.887338</td>\n",
       "      <td>0.887413</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>136</td>\n",
       "      <td>0.891380</td>\n",
       "      <td>0.884903</td>\n",
       "      <td>0.895916</td>\n",
       "      <td>0.890733</td>\n",
       "      <td>0.004519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.852647</td>\n",
       "      <td>0.052690</td>\n",
       "      <td>0.264987</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904382</td>\n",
       "      <td>0.893320</td>\n",
       "      <td>0.897043</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>86</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.900349</td>\n",
       "      <td>0.900896</td>\n",
       "      <td>0.900863</td>\n",
       "      <td>0.000407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.749457</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>0.473530</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892430</td>\n",
       "      <td>0.885344</td>\n",
       "      <td>0.888408</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>132</td>\n",
       "      <td>0.891380</td>\n",
       "      <td>0.892875</td>\n",
       "      <td>0.894422</td>\n",
       "      <td>0.892892</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2.403066</td>\n",
       "      <td>0.032255</td>\n",
       "      <td>0.556340</td>\n",
       "      <td>0.042589</td>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918327</td>\n",
       "      <td>0.908275</td>\n",
       "      <td>0.910328</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>16</td>\n",
       "      <td>0.975087</td>\n",
       "      <td>0.975087</td>\n",
       "      <td>0.972610</td>\n",
       "      <td>0.974261</td>\n",
       "      <td>0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>4.913290</td>\n",
       "      <td>0.158064</td>\n",
       "      <td>1.318622</td>\n",
       "      <td>0.035868</td>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913347</td>\n",
       "      <td>0.906281</td>\n",
       "      <td>0.908335</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>22</td>\n",
       "      <td>0.976582</td>\n",
       "      <td>0.978575</td>\n",
       "      <td>0.975598</td>\n",
       "      <td>0.976918</td>\n",
       "      <td>0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2.945695</td>\n",
       "      <td>0.035838</td>\n",
       "      <td>0.725745</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918327</td>\n",
       "      <td>0.920239</td>\n",
       "      <td>0.914980</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980568</td>\n",
       "      <td>0.980070</td>\n",
       "      <td>0.980578</td>\n",
       "      <td>0.980405</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>4.316001</td>\n",
       "      <td>0.211861</td>\n",
       "      <td>1.272064</td>\n",
       "      <td>0.070193</td>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914343</td>\n",
       "      <td>0.904287</td>\n",
       "      <td>0.908667</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>21</td>\n",
       "      <td>0.976582</td>\n",
       "      <td>0.979073</td>\n",
       "      <td>0.975100</td>\n",
       "      <td>0.976918</td>\n",
       "      <td>0.001640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2.666209</td>\n",
       "      <td>0.030241</td>\n",
       "      <td>0.594277</td>\n",
       "      <td>0.110172</td>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916335</td>\n",
       "      <td>0.919242</td>\n",
       "      <td>0.913320</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>5</td>\n",
       "      <td>0.980568</td>\n",
       "      <td>0.981066</td>\n",
       "      <td>0.981076</td>\n",
       "      <td>0.980903</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         1.633313      0.003763         0.486775        0.010979   \n",
       "1         1.359614      0.121083         0.430986        0.145028   \n",
       "2         1.363829      0.124363         0.471265        0.077995   \n",
       "3         0.852647      0.052690         0.264987        0.011226   \n",
       "4         1.749457      0.040503         0.473530        0.023937   \n",
       "..             ...           ...              ...             ...   \n",
       "155       2.403066      0.032255         0.556340        0.042589   \n",
       "156       4.913290      0.158064         1.318622        0.035868   \n",
       "157       2.945695      0.035838         0.725745        0.012690   \n",
       "158       4.316001      0.211861         1.272064        0.070193   \n",
       "159       2.666209      0.030241         0.594277        0.110172   \n",
       "\n",
       "                                             param_clf param_clf__C  \\\n",
       "0               LogisticRegression(solver='liblinear')          0.5   \n",
       "1               LogisticRegression(solver='liblinear')          0.5   \n",
       "2               LogisticRegression(solver='liblinear')          0.5   \n",
       "3               LogisticRegression(solver='liblinear')          0.5   \n",
       "4               LogisticRegression(solver='liblinear')          0.5   \n",
       "..                                                 ...          ...   \n",
       "155  VotingClassifier(estimators=[('lr', LogisticRe...          NaN   \n",
       "156  VotingClassifier(estimators=[('lr', LogisticRe...          NaN   \n",
       "157  VotingClassifier(estimators=[('lr', LogisticRe...          NaN   \n",
       "158  VotingClassifier(estimators=[('lr', LogisticRe...          NaN   \n",
       "159  VotingClassifier(estimators=[('lr', LogisticRe...          NaN   \n",
       "\n",
       "    param_clf__penalty param_vect__max_df param_vect__max_features  \\\n",
       "0                   l1                0.9                      300   \n",
       "1                   l1                0.9                      300   \n",
       "2                   l1                0.9                      300   \n",
       "3                   l1                0.9                      300   \n",
       "4                   l1                0.9                      500   \n",
       "..                 ...                ...                      ...   \n",
       "155                NaN                0.8                      300   \n",
       "156                NaN                0.8                      500   \n",
       "157                NaN                0.8                      500   \n",
       "158                NaN                0.8                      500   \n",
       "159                NaN                0.8                      500   \n",
       "\n",
       "    param_vect__ngram_range  ... split1_test_score split2_test_score  \\\n",
       "0                    (1, 3)  ...          0.886454          0.886341   \n",
       "1                    (1, 3)  ...          0.904382          0.893320   \n",
       "2                    (1, 2)  ...          0.887450          0.887338   \n",
       "3                    (1, 2)  ...          0.904382          0.893320   \n",
       "4                    (1, 3)  ...          0.892430          0.885344   \n",
       "..                      ...  ...               ...               ...   \n",
       "155                  (1, 2)  ...          0.918327          0.908275   \n",
       "156                  (1, 3)  ...          0.913347          0.906281   \n",
       "157                  (1, 3)  ...          0.918327          0.920239   \n",
       "158                  (1, 2)  ...          0.914343          0.904287   \n",
       "159                  (1, 2)  ...          0.916335          0.919242   \n",
       "\n",
       "    mean_test_score std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.886748       0.000498              138            0.891380   \n",
       "1          0.897043       0.005190               86            0.901345   \n",
       "2          0.887413       0.000053              136            0.891380   \n",
       "3          0.897043       0.005190               86            0.901345   \n",
       "4          0.888408       0.002971              132            0.891380   \n",
       "..              ...            ...              ...                 ...   \n",
       "155        0.910328       0.005875               16            0.975087   \n",
       "156        0.908335       0.003563               22            0.976582   \n",
       "157        0.914980       0.006135                1            0.980568   \n",
       "158        0.908667       0.004206               21            0.976582   \n",
       "159        0.913320       0.006430                5            0.980568   \n",
       "\n",
       "     split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0              0.884903            0.895916          0.890733         0.004519  \n",
       "1              0.899851            0.900896          0.900697         0.000626  \n",
       "2              0.884903            0.895916          0.890733         0.004519  \n",
       "3              0.900349            0.900896          0.900863         0.000407  \n",
       "4              0.892875            0.894422          0.892892         0.001242  \n",
       "..                  ...                 ...               ...              ...  \n",
       "155            0.975087            0.972610          0.974261         0.001168  \n",
       "156            0.978575            0.975598          0.976918         0.001239  \n",
       "157            0.980070            0.980578          0.980405         0.000237  \n",
       "158            0.979073            0.975100          0.976918         0.001640  \n",
       "159            0.981066            0.981076          0.980903         0.000237  \n",
       "\n",
       "[160 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Metrics With Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity/Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
